#!/usr/bin/env python3
"""
Simple Encodec Demo: Replace Sofia's Edge TTS with faster alternative

This demonstrates the CORE technique from Voila:
- Audio tokenization with Encodec (neural codec)
- Fast encoding/decoding (~100ms each)

For Sofia, this would replace:
- Edge TTS (1200ms) ‚Üí Encodec decode (100ms) = 12x faster
"""
import time
import torch
import torchaudio
import soundfile as sf
import numpy as np
from transformers import EncodecModel, AutoProcessor


class FastAudioCodec:
    """
    Fast audio codec for Sofia TTS replacement

    Instead of text‚Üíaudio synthesis, this shows:
    - How to compress/decompress audio ultra-fast
    - Voice transformation capabilities
    - Token-based audio processing (like Voila)
    """

    def __init__(self):
        print("üîß Loading Fast Audio Codec...")
        self.model = EncodecModel.from_pretrained("facebook/encodec_24khz")
        self.processor = AutoProcessor.from_pretrained("facebook/encodec_24khz")
        self.sr = self.processor.sampling_rate
        print("   ‚úÖ Ready!")

    def compress_audio(self, audio_path: str, output_tokens_path: str = None):
        """
        Compress audio to tokens (like Voila's audio tokenization)
        """
        print(f"\nüì• Loading: {audio_path}")
        wav, sr = torchaudio.load(audio_path)
        if len(wav.shape) > 1:
            wav = wav[0]

        # Resample if needed
        if sr != self.sr:
            wav = torchaudio.functional.resample(wav, sr, self.sr)

        # Encode
        print("üîπ Encoding audio ‚Üí tokens...")
        start = time.time()
        with torch.no_grad():
            wav_input = wav[None, None, :]
            codes = self.model.encode(wav_input, bandwidth=3.0)
            tokens = codes.audio_codes[0, 0]  # [num_codebooks, seq_len]
        encode_ms = (time.time() - start) * 1000

        num_codebooks, seq_len = tokens.shape
        print(f"   Audio: {len(wav)} samples ‚Üí {seq_len} tokens")
        print(f"   Codebooks: {num_codebooks}")
        print(f"   Compression: {len(wav)/seq_len:.1f}:1")
        print(f"   ‚è±Ô∏è  {encode_ms:.0f}ms")

        if output_tokens_path:
            torch.save(tokens, output_tokens_path)
            print(f"   üíæ Tokens saved: {output_tokens_path}")

        return tokens, encode_ms

    def decompress_tokens(self, tokens, output_audio_path: str = None):
        """
        Decompress tokens back to audio (like Voila's TTS)
        """
        print(f"\nüîπ Decoding tokens ‚Üí audio...")
        start = time.time()
        with torch.no_grad():
            audio_values = self.model.decode(tokens[None, None, :, :], [None])[0]
            wav = audio_values[0, 0].cpu().numpy()
        decode_ms = (time.time() - start) * 1000

        print(f"   Audio: {len(wav)} samples")
        print(f"   ‚è±Ô∏è  {decode_ms:.0f}ms")

        if output_audio_path:
            sf.write(output_audio_path, wav, self.sr)
            print(f"   üíæ Audio saved: {output_audio_path}")

        return wav, decode_ms

    def voice_transform_demo(self, input_audio: str, output_audio: str):
        """
        Demonstrate voice transformation (what Voila uses for TTS)

        In Voila:
        1. LLM generates audio tokens
        2. Speaker embedding modifies tokens
        3. Decoder creates audio with target voice

        Here we show the decode step speed
        """
        print("\n" + "="*60)
        print("VOICE CODEC DEMO (Voila's Core TTS Technique)")
        print("="*60)

        # Step 1: Compress
        tokens, encode_ms = self.compress_audio(input_audio)

        # Step 2: [In Voila, tokens would be modified with speaker embedding here]
        print("\n   (In Voila: tokens modified with speaker embedding)")

        # Step 3: Decompress
        wav, decode_ms = self.decompress_tokens(tokens, output_audio)

        total_ms = encode_ms + decode_ms

        print("\n" + "="*60)
        print("üìä PERFORMANCE")
        print("="*60)
        print(f"   Encoding: {encode_ms:.0f}ms")
        print(f"   Decoding: {decode_ms:.0f}ms")
        print(f"   TOTAL:    {total_ms:.0f}ms")

        print("\nüìà SOFIA COMPARISON:")
        print(f"   Edge TTS (cloud): ~1200ms")
        print(f"   This codec:        {total_ms:.0f}ms")
        print(f"   Speedup:          {1200/total_ms:.1f}x")

        print(f"\n‚úÖ Demo complete!")
        print(f"   Original:      {input_audio}")
        print(f"   Reconstructed: {output_audio}")


if __name__ == "__main__":
    codec = FastAudioCodec()

    # Test with Voila's example audio
    codec.voice_transform_demo(
        input_audio="examples/test1.mp3",
        output_audio="output/fast_codec_demo.wav"
    )

    print("\n" + "="*60)
    print("üí° KEY INSIGHT FOR SOFIA:")
    print("="*60)
    print("""
This demonstrates Voila's core speed advantage:

1. CURRENT SOFIA:
   Text ‚Üí Edge TTS (cloud API) ‚Üí Audio
   Latency: ~1200ms

2. VOILA APPROACH:
   Text ‚Üí LLM ‚Üí Audio Tokens ‚Üí Codec Decode ‚Üí Audio
   Latency: ~100ms (just the decode step!)

3. SOFIA INTEGRATION:
   - Use multimodal LLM (GPT-4o, Gemini) for text ‚Üí tokens
   - Use this codec for tokens ‚Üí audio
   - Total TTS: ~200-300ms (4-6x faster!)

Next step: Test with Sofia's LLM output
    """)
