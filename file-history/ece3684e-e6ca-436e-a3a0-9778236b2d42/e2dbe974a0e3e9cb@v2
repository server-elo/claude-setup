# Sofia + Voila Integration Analysis

**Date:** 2025-10-01
**Goal:** Test Voila (Option C) ‚Üí Extract principles (Option B) ‚Üí Apply to Sofia

---

## üìä Voila Repository Analysis

### **What We Found:**

**Repository:** `maitrix-org/Voila`
**License:** Open Source
**Released:** April 28, 2025

### **Available Models:**

| Model | Purpose | Use for Sofia |
|-------|---------|---------------|
| **Voila-base** | Base model | General voice-language |
| **Voila-chat** | End-to-end audio chat | ‚úÖ **Best for Sofia** |
| **Voila-autonomous** | Full-duplex audio | Advanced real-time |
| **Voila-audio-alpha** | Raw audio input | Audio understanding |
| **Voila-tokenizer** | Audio tokenizer | Required dependency |

### **Key Files:**

```
voila-test/
‚îú‚îÄ‚îÄ infer.py                    # Inference script
‚îú‚îÄ‚îÄ model.py                    # Core model architecture (61KB!)
‚îú‚îÄ‚îÄ audio_transformer.py        # Audio processing
‚îú‚îÄ‚îÄ voila_tokenizer.py          # Audio tokenization
‚îú‚îÄ‚îÄ spkr.py                     # Speaker embeddings
‚îú‚îÄ‚îÄ gradio_demo.py             # Interactive demo
‚îî‚îÄ‚îÄ examples/
    ‚îú‚îÄ‚îÄ test1.mp3              # Test audio
    ‚îî‚îÄ‚îÄ test_autonomous1.mp3   # Autonomous test
```

---

## üéØ Voila Features (Relevant to Sofia)

### **1. Low Latency: 195ms**
- **How:** End-to-end architecture (no pipeline delays)
- **vs Sofia current:** ~3000-5000ms (15-25x slower!)

### **2. Voice Customization**
- **From:** 10-second audio sample
- **Perfect for:** Hotel receptionist persona
- **Million voices:** Pre-built voice library

### **3. Multiple Tasks**
- ‚úÖ Voice chat (what Sofia needs)
- ‚úÖ ASR (speech-to-text)
- ‚úÖ TTS (text-to-speech)
- ‚úÖ Speech translation
- ‚úÖ Unified model (no separate components)

### **4. Benchmark Results**

| Metric | Voila | Competitors | Sofia Current |
|--------|-------|-------------|---------------|
| **Voila Benchmark** | 30.56 | Moshi: 11.45, SpeechGPT: 13.29 | N/A |
| **ASR (WER)** | 4.8% | Moshi: 5.7%, Whisper: 2.7% | ~5-10% (est.) |
| **TTS (WER)** | 3.2% | Moshi: 4.7%, Vall-E: 5.9% | N/A |
| **Latency** | **195ms** | Moshi: ~200-300ms | **3000-5000ms** |

---

## üß™ Testing Plan (Option C)

### **Step 1: Install Dependencies**
```bash
cd ~/Desktop/elvi/sofia-pers/voila-test
python3 -m venv .venv
source .venv/bin/activate
pip install torch torchvision torchaudio transformers
pip install flash-attn soundfile librosa jsonlines gradio pyannote.audio
```

**Note:** Requires CUDA GPU for optimal performance

### **Step 2: Test Voice Chat**
```bash
# Download model (auto-downloads from HuggingFace)
python infer.py \
    --model-name "maitrix-org/Voila-chat" \
    --input-audio "examples/test1.mp3" \
    --task-type chat_aiao
```

### **Step 3: Test Latency**
```bash
# Measure actual response time
time python infer.py \
    --model-name "maitrix-org/Voila-chat" \
    --input-audio "examples/test1.mp3" \
    --task-type chat_aiao
```

### **Step 4: Test Voice Customization**
```bash
# Create hotel receptionist voice from 10-sec sample
# (Need to create sample first)
```

### **Step 5: Test Gradio Demo**
```bash
python gradio_demo.py
# Opens interactive web UI for testing
```

---

## üî¨ Architecture Analysis (Option B - After Testing)

### **Key Techniques to Extract:**

From `model.py` (61KB - complex architecture):

1. **Hierarchical Multi-Scale Transformer**
   - Multiple attention layers at different scales
   - Semantic + acoustic token separation

2. **Audio Tokenization**
   - RVQ (Residual Vector Quantization)
   - 4-layer tokenizer
   - Semantic vs acoustic disentanglement

3. **End-to-End Integration**
   - No separate ASR ‚Üí LLM ‚Üí TTS pipeline
   - Direct audio-to-audio processing
   - Unified model weights

4. **Streaming Architecture**
   - Real-time audio encoding
   - Incremental token generation
   - Full-duplex support (autonomous model)

5. **Speaker Embeddings**
   - Voice identity from audio samples
   - Character reference embeddings
   - Fast voice switching

---

## üé® Sofia Adaptation Strategy (After Analysis)

### **Option 1: Direct Integration**
**Use Voila models directly for Sofia**

**Pros:**
- ‚úÖ Instant 195ms latency
- ‚úÖ Production-ready models
- ‚úÖ Voice customization built-in
- ‚úÖ Proven performance

**Cons:**
- ‚ùå Requires GPU (CUDA)
- ‚ùå Large model download (~several GB)
- ‚ùå Need to adapt for German/hotel domain

**Implementation:**
```python
# Sofia with Voila backend
from voila import VoilaModel

class SofiaVoilaHandler:
    def __init__(self):
        self.model = VoilaModel.from_pretrained("maitrix-org/Voila-chat")
        self.customize_voice()  # Hotel receptionist voice

    def handle_conversation(self, audio_input):
        # Direct audio-to-audio
        response = self.model.chat(audio_input)
        return response  # ~195ms total
```

---

### **Option 2: Hybrid Approach**
**Use Voila architecture principles + Sofia's current stack**

**Apply Voila techniques to Sofia:**

1. **Reduce Pipeline Stages**
   - Current: Audio ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio (4 stages)
   - Voila: Audio ‚Üí Unified Model ‚Üí Audio (1 stage)
   - Sofia hybrid: Merge STT+LLM or LLM+TTS

2. **Add Audio Tokenization**
   - Use Voila tokenizer for audio
   - Process audio tokens directly (like Voila)
   - Reduce text conversion overhead

3. **Implement Streaming**
   - Current: Wait for full utterance
   - Voila: Stream audio incrementally
   - Sofia: Add incremental processing

4. **Voice Embeddings**
   - Create hotel receptionist voice profile
   - Use speaker embeddings like Voila
   - Fast persona switching

---

### **Option 3: Learn & Rebuild**
**Study Voila, rebuild key concepts for Sofia**

**Extract patterns:**
- Hierarchical transformer design
- Multi-scale attention
- Audio tokenization approach
- End-to-end training methodology

**Implement in Sofia:**
- Simplified version for CPU
- German-specific optimizations
- Hotel domain fine-tuning

---

## üìã Requirements Analysis

### **Hardware:**
```
Voila Requirements:
- GPU: CUDA-capable (NVIDIA)
- RAM: 16GB+ recommended
- Storage: ~10-20GB for models

Sofia Current:
- CPU: Any modern processor
- RAM: 4GB minimum
- Storage: ~2GB
```

**Decision Point:** Do we have GPU access?
- **Yes:** Use Voila models directly (Option 1)
- **No:** Extract principles only (Option 2/3)

---

## üöÄ Next Steps

### **Immediate (Testing - Option C):**
1. ‚úÖ Clone repository - DONE
2. ‚úÖ Install dependencies - DONE (torch, transformers, etc)
3. ‚ö†Ô∏è Run basic inference test - **BLOCKED**
4. ‚è≥ Measure latency
5. ‚è≥ Test voice customization
6. ‚è≥ Try Gradio demo

### **Testing Issues Encountered:**

**Issue 1: GPU Dependency**
- Voila is designed for CUDA GPUs
- Mac uses CPU (ARM64/Apple Silicon)
- Modified infer.py to use CPU instead of CUDA

**Issue 2: PyTorch Version Incompatibility**
```
AttributeError: 'DynamicCache' object has no attribute 'seen_tokens'
```
- Model code expects PyTorch 2.4.x API
- Current PyTorch 2.8.0 has changed DynamicCache interface
- Voila code not updated for latest PyTorch

**Issue 3: Flash Attention**
- `use_flash_attention_2=True` not supported by VoilaModel
- Removed this parameter

**Issue 4: TorchCodec FFmpeg**
- Missing FFmpeg libraries (libavutil versions 56-59)
- Not critical for our testing (using mp3 directly)

**Conclusion:** Voila testing on Mac CPU is not straightforward. GPU required for optimal performance. **Recommend proceeding to Option B** (extract principles from code analysis).

### **After Testing (Analysis - Option B):**
1. Read `model.py` in detail
2. Understand audio_transformer.py
3. Study tokenization approach
4. Map to Sofia's architecture
5. Extract applicable techniques
6. Design integration plan

### **Final (Implementation):**
1. Choose integration strategy (1, 2, or 3)
2. Implement chosen approach
3. Test with hotel scenarios
4. Benchmark improvements
5. Deploy

---

## üéØ Success Criteria

**Option C (Testing) Complete When:**
- ‚úÖ Voila runs successfully
- ‚úÖ Latency measured (validate 195ms claim)
- ‚úÖ Voice chat works
- ‚úÖ Architecture understood

**Option B (Analysis) Complete When:**
- ‚úÖ Key techniques extracted
- ‚úÖ Adaptation plan designed
- ‚úÖ Implementation path clear
- ‚úÖ Sofia integration strategy defined

---

## üìù Status

**Current Phase:** Option C - Testing
**Next Phase:** Option B - Architecture Analysis
**Final Phase:** Sofia Integration

**Progress:** 20% (Repository cloned, README analyzed)

---

**Last Updated:** 2025-10-01 13:16
**Document:** SOFIA_VOILA_ANALYSIS.md
