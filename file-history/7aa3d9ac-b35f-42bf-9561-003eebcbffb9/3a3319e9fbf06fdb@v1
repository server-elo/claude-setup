# Runtime Guardrail Proxy + Auto-Remediation PRs

A drop-in reverse proxy that redacts PII, enforces tool policies, and auto-opens PRs to fix what your Red-Team CI finds.

## Overview

The Runtime Guardrail Proxy is a security-focused middleware that sits between your application and LLM providers (like Anthropic or OpenAI). It provides real-time protection against common LLM vulnerabilities by:

1. **Redacting PII/secrets** via regex patterns and masking them inline
2. **Enforcing tool policies** with deny-by-default and per-tool/arg whitelists
3. **Blocking oversized payloads** and enforcing environment constraints
4. **Logging structured decisions** without exposing sensitive data
5. **Auto-generating remediation PRs** when CI detects issues

This proxy is designed to complement your CI/CD pipeline by providing runtime protection against issues that your Red-Team CI identifies.

## Quick Start

### Prerequisites

- Python 3.11+
- Docker (optional)
- GitHub CLI (for auto-remediation PR feature)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/guardrail-proxy.git
cd guardrail-proxy

# Install dependencies
pip install poetry
poetry install
```

### Running the Proxy

```bash
# Set your LLM provider API key
export PROVIDER_API_KEY=your_api_key_here
export PROVIDER=anthropic  # or openai

# Run the proxy
uvicorn app.main:app --host 0.0.0.0 --port 8080
```

### Using Docker

```bash
# Build the Docker image
docker build -t guardrail .

# Run the container
docker run -d -p 8080:8080 \
  -e PROVIDER_API_KEY=your_api_key_here \
  -e PROVIDER=anthropic \
  guardrail
```

## Configuration

The proxy is configured using a YAML policy file. By default, it looks for `app/policy.yaml`, but you can specify a different path using the `POLICY_PATH` environment variable.

### Sample Policy

```yaml
version: "1.0.0"
pii_patterns:
  EMAIL:    '(?i)\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b'
  PHONE:    '\b(?:\+?\d{1,3}[-.\s]?)?(?:\(?\d{3}\)?[-.\s]?)?\d{3}[-.\s]?\d{4}\b'
  SSN:      '\b\d{3}-\d{2}-\d{4}\b'
  CARD:     '\b(?:\d[ -]*?){13,16}\b'
  ACCESS_KEY: 'AKIA[0-9A-Z]{16}'
redaction:
  strategy: token
  token_format: "[REDACTED:{TYPE}]"
tools:
  default: deny
  allow:
    - name: search
      args_schema: {}
    - name: writeFile
      args_schema:
        external_write: { enum: [false] }
        path: { pattern: '^(?!\.\.).+' }
limits:
  max_kb: 64
  max_model_tokens: 4000
audit:
  log_payloads: masked
  retention_days: 30
environments:
  require_header: { name: "X-Environment", value: "staging" }
```

## API Usage

### Chat Endpoint

```bash
curl -X POST http://localhost:8080/chat \
  -H "Content-Type: application/json" \
  -H "X-Environment: staging" \
  -d '{
    "user_input": "Hello, my email is user@example.com",
    "intended_tool_calls": [
      {
        "tool": "search",
        "args": {}
      }
    ],
    "model": "claude-3-5-sonnet-20240620"
  }'
```

### Health Check

```bash
curl http://localhost:8080/healthz
```

## Auto-Remediation PRs

The auto-remediation feature automatically generates pull requests to fix policy violations detected by your Red-Team CI.

### Usage

```bash
python scripts/generate_guardrail_pr.py \
  --repo owner/repo \
  --verdict path/to/verdicts.json \
  --branch fix/guardrail-123
```

### CI Integration

Add the following to your CI workflow:

```yaml
- name: Spin up Guardrail Proxy
  run: docker build -t guardrail . && docker run -d -p 8080:8080 --name guardrail -e PROVIDER_API_KEY=${{ secrets.PROVIDER_API_KEY }} guardrail
  
- name: Re-run top repro via proxy
  run: bash scripts/repro_through_proxy.sh artifacts/top_repro.json
  
- name: Create guardrail PR
  if: failure()
  run: python scripts/generate_guardrail_pr.py --repo ${{ github.repository }} --verdict artifacts/verdicts.json --branch fix/guardrail-${{ github.run_id }}
```

## Architecture

```
Caller → Guardrail Proxy (FastAPI/Worker)
        ├─ Hot path PDP (regex/arg schema, no LLM)
        │   ├─ decision=allow/allow_with_redaction → call Provider API
        │   └─ decision=deny → 403 + rationale
        ├─ Logging: decision + policy_version + redactions[] (masked)
        └─ Async sampler → Judge (LLM) → policy_suggestions table → Auto-Remediation PRs
```

## Performance

- 95p proxy overhead ≤ 50ms
- p99 ≤ 100ms
- No LLM calls on hot path

## Security Considerations

- The proxy does not store raw user inputs or secrets
- All PII is redacted before logging
- Tool policies follow deny-by-default principle
- Environment header prevents accidental production usage
- Size limits prevent DoS attacks

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.