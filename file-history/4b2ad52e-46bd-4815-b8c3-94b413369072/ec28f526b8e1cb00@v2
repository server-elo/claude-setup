# üéØ Moshi Integration Plan for Sofia-Local

## Executive Summary

Sofia-local already has excellent optimization (`console_handler_optimized.py`), but still depends on cloud APIs. This plan integrates Moshi's streaming techniques for a **100% local, ultra-low latency** German voice AI.

## Current State (As of October 1, 2025)

### ‚úÖ What Sofia Has
1. **Optimized STT**: `stt_optimized.py` uses faster-whisper (4x faster than standard Whisper)
2. **VAD**: WebRTC VAD with automatic speech detection
3. **LLM**: Local Ollama (gemma2:2b) with streaming
4. **Pipeline**: 5 parallel threads for overlapping execution
5. **Performance Tracking**: Metrics against research papers (WhisperKit, VoXtream, Voila)

### ‚ùå What Sofia Lacks
1. **Local TTS**: Still uses Edge-TTS (cloud API) ‚Üê **CRITICAL BOTTLENECK**
2. **Streaming Codec**: No audio codec optimization like Moshi's Mimi
3. **Full-Duplex**: Cannot handle interruptions mid-response

### üìä Current Performance
- **Target**: <1000ms end-to-end
- **Actual**: Unknown (needs benchmarking)
- **Bottleneck**: Edge-TTS cloud API (likely 200-500ms + network latency)

## Moshi Learnings Applied

### Key Insights from Moshi
1. **Mimi Codec** (`rustymimi`): Streaming neural audio codec
   - 80ms frame size = 80ms latency
   - 1.1 kbps compression
   - Preserves quality + emotion

2. **Streaming Architecture**:
   - Client-server with queues
   - Frame-by-frame processing (no batch accumulation)
   - Warmup procedure for codec

3. **Performance**:
   - 160-200ms total latency
   - 24kHz audio (same as sofia's Edge-TTS)
   - Full-duplex (simultaneous listen + speak)

## Implementation Phases

### Phase 1: LOCAL TTS (CRITICAL) ‚úÖ CREATED
**File**: `src/voice/tts_piper_local.py`

**What**:
- Replace Edge-TTS with Piper German TTS (Thorsten voice)
- 100% local, zero cloud dependency
- Sentence-by-sentence streaming

**Impact**:
- ‚úÖ Remove cloud API latency (200-500ms)
- ‚úÖ 100% privacy (no data sent to cloud)
- ‚úÖ Consistent performance (no network dependency)

**Implementation**:
```python
from .tts_piper_local import PiperLocalTTS

# In console_handler_optimized.py:
self.tts = PiperLocalTTS(voice_model="de_DE-thorsten-medium")
```

**Requirements**:
```bash
pip install piper-tts
# Or download binary from: https://github.com/rhasspy/piper/releases
```

**Benchmarks to Run**:
- TTS first-packet latency
- Total TTS generation time
- Audio quality (subjective)
- CPU usage

### Phase 2: STREAMING CODEC (OPTIONAL)
**What**:
- Integrate `rustymimi` for audio codec
- Stream audio frame-by-frame (80ms chunks)
- Reduce buffer accumulation

**Impact**:
- Lower perceived latency
- Better for interruptions
- Moshi-level responsiveness

**Implementation**:
```bash
pip install rustymimi
```

**Usage**:
```python
import rustymimi

# Encode audio for transmission
encoder = rustymimi.Encoder(sample_rate=24000)
encoded = encoder.encode(pcm_audio)

# Decode audio for playback
decoder = rustymimi.Decoder()
decoded = decoder.decode(encoded)
```

**When to Do This**:
- After Phase 1 is working
- If latency is still >500ms
- If you want Moshi-level performance

### Phase 3: FULL-DUPLEX (ADVANCED)
**What**:
- Handle interruptions mid-response
- Two-stream architecture (like Moshi)
- Stop TTS when user starts speaking

**Impact**:
- Natural conversation flow
- Human-like interactions
- Moshi-level UX

**Implementation Complexity**: High
**Priority**: Low (nice-to-have)

## Immediate Action Plan

### Step 1: Install Piper TTS
```bash
cd ~/Desktop/elvi/sofia-pers/sofia-local
source .venv/bin/activate
pip install piper-tts
```

### Step 2: Test Local TTS
```bash
python src/voice/tts_piper_local.py
```

**Expected Output**:
```
‚úÖ Piper TTS found: piper 1.3.0
‚úÖ Piper Local TTS initialized
‚úÖ Generated X bytes
‚úÖ Streaming test complete
```

### Step 3: Integrate with Optimized Handler
```python
# Edit: src/voice/console_handler_optimized.py
# Line 57: Change TTS import

# OLD:
from .tts_voxtream import VoXtreamTTS
self.tts = VoXtreamTTS(voice="de-DE-KatjaNeural")

# NEW:
from .tts_piper_local import PiperLocalTTS
self.tts = PiperLocalTTS(voice_model="de_DE-thorsten-medium")
```

### Step 4: Test End-to-End
```bash
cd ~/Desktop/elvi/sofia-pers/sofia-local
python agent.py console
```

**Say**: "Guten Tag, ich h√§tte gerne ein Zimmer"

**Expected**:
- Automatic speech detection (VAD)
- Fast transcription (<500ms)
- LLM response
- LOCAL TTS (no internet needed)
- Total latency: <1000ms

### Step 5: Benchmark Performance
```python
# Performance metrics are already tracked in console_handler_optimized.py
# Check self.latency_stats after each interaction:
# - stt_complete: Should be <500ms
# - tts_first_packet: Should be <150ms
# - total_response: Should be <1000ms
```

## Success Criteria

### Minimum Viable Product (MVP)
- [x] Local TTS file created (`tts_piper_local.py`)
- [ ] Piper TTS installed and tested
- [ ] Integrated with console_handler_optimized.py
- [ ] End-to-end test passes
- [ ] Latency <1500ms (better than current)

### Target Performance
- [ ] STT latency <500ms (WhisperKit target)
- [ ] TTS first-packet <150ms (VoXtream target)
- [ ] Total latency <1000ms (Voila-inspired)
- [ ] 100% local (zero cloud APIs)

### Stretch Goals
- [ ] rustymimi integration
- [ ] Frame-by-frame streaming
- [ ] Full-duplex interruption handling
- [ ] Latency <200ms (Moshi-level)

## Comparison Matrix

| Feature | Current Sofia | With Piper | With Moshi Full Integration |
|---------|---------------|------------|----------------------------|
| **STT** | faster-whisper | ‚úÖ faster-whisper | Mimi codec |
| **TTS** | Edge-TTS (cloud) | ‚úÖ Piper (local) | ‚úÖ Mimi codec |
| **Latency** | ~1-2s | <1s | <200ms |
| **Privacy** | ‚ö†Ô∏è Partial | ‚úÖ 100% | ‚úÖ 100% |
| **Full-Duplex** | ‚ùå No | ‚ùå No | ‚úÖ Yes |
| **Cloud Dependency** | ‚ùå Yes (TTS) | ‚úÖ No | ‚úÖ No |
| **Complexity** | Medium | Medium | High |

## Technical Architecture

### Current Sofia Pipeline
```
User Speech
  ‚Üì (PyAudio)
WebRTC VAD (detect speech start/end)
  ‚Üì
faster-whisper STT (16kHz ‚Üí text)
  ‚Üì
Ollama LLM (text ‚Üí response text)
  ‚Üì
Edge-TTS API (text ‚Üí audio) ‚Üê CLOUD BOTTLENECK
  ‚Üì (PyAudio)
Speaker Output
```

### Optimized Pipeline (Phase 1)
```
User Speech
  ‚Üì (PyAudio)
WebRTC VAD
  ‚Üì
faster-whisper STT (German)
  ‚Üì
Ollama LLM (streaming tokens)
  ‚Üì
Piper Local TTS (Thorsten) ‚Üê 100% LOCAL
  ‚Üì (PyAudio)
Speaker Output
```

### Future: Moshi-Inspired Pipeline (Phase 2+3)
```
User Speech
  ‚Üì
rustymimi encoder (frame-by-frame)
  ‚Üì
Custom ASR or faster-whisper
  ‚Üì
Ollama LLM (streaming)
  ‚Üì
rustymimi decoder (frame-by-frame)
  ‚Üì
Speaker Output (with interruption support)
```

## Files Created

1. **`src/voice/tts_piper_local.py`** ‚úÖ
   - Local German TTS with Piper
   - Streaming support
   - Moshi-inspired architecture

2. **`MOSHI_INTEGRATION_PLAN.md`** ‚úÖ
   - This document
   - Complete integration roadmap

3. **`~/Desktop/moshi/MOSHI_TEST_RESULTS.md`** ‚úÖ
   - Moshi testing results
   - Performance benchmarks

## Resources

### Moshi
- **Paper**: https://arxiv.org/abs/2410.00037
- **GitHub**: https://github.com/kyutai-labs/moshi
- **Live Demo**: https://moshi.chat
- **Models**: https://huggingface.co/kyutai

### Piper TTS
- **GitHub**: https://github.com/rhasspy/piper
- **Voices**: https://huggingface.co/rhasspy/piper-voices
- **Thorsten Voice**: https://github.com/thorstenMueller/Thorsten-Voice

### Sofia-Local
- **Location**: `~/Desktop/elvi/sofia-pers/sofia-local/`
- **Optimized Handler**: `src/voice/console_handler_optimized.py`
- **Current State**: Research-backed, but cloud-dependent TTS

## Next Steps

1. **Immediate** (Today):
   - Install Piper TTS
   - Test tts_piper_local.py
   - Verify audio quality

2. **Short Term** (This Week):
   - Integrate with console_handler_optimized.py
   - End-to-end testing
   - Benchmark latency

3. **Medium Term** (Next Week):
   - Optimize for <1000ms latency
   - Test with real hotel scenarios
   - User acceptance testing

4. **Long Term** (Future):
   - rustymimi integration
   - Full-duplex support
   - Approach Moshi-level performance (<200ms)

## Conclusion

Sofia-local is **90% there** - it has excellent optimization infrastructure, but the final 10% (local TTS) will unlock:
- ‚úÖ True 100% privacy
- ‚úÖ Zero cloud dependency
- ‚úÖ Consistent low latency
- ‚úÖ Moshi-level responsiveness

**The hybrid approach is the winner**: Keep Sofia's German language support, add Moshi's streaming techniques, replace cloud TTS with local Piper.

**Time to Implementation**: 1-2 hours
**Complexity**: Low
**Impact**: HIGH üöÄ

---

**Status**: Phase 1 READY - Local TTS file created
**Next Action**: Install Piper TTS and test
**Date**: October 1, 2025
