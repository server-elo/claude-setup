"""
Text-to-Speech Module using Kokoro
Wrapper around fastrtc's TTS model
"""
from fastrtc import get_tts_model
import numpy as np


class TextToSpeech:
    def __init__(self):
        """Initialize Kokoro TTS model"""
        print("üîä Loading Kokoro TTS model...")
        self.model = get_tts_model()  # Kokoro v1.0 ONNX
        print("‚úÖ Kokoro TTS loaded successfully")

    def synthesize(self, text):
        """
        Synthesize text to speech (streaming)

        Args:
            text (str): Text to convert to speech

        Yields:
            Audio chunks as bytes (converted from numpy arrays)
        """
        try:
            for sample_rate, audio_array in self.model.stream_tts_sync(text):
                # Convert numpy array to bytes for PyAudio
                # audio_array is float32, need to convert to int16
                audio_int16 = (audio_array * 32767).astype(np.int16)
                audio_bytes = audio_int16.tobytes()
                yield audio_bytes
        except Exception as e:
            print(f"‚ùå TTS Error: {e}")
            import traceback
            traceback.print_exc()
            return

    def synthesize_blocking(self, text):
        """
        Synthesize text to speech (blocking, returns all audio)

        Args:
            text (str): Text to convert to speech

        Returns:
            bytes: Complete audio data
        """
        audio_chunks = []
        for chunk in self.synthesize(text):
            audio_chunks.append(chunk)
        return b''.join(audio_chunks) if audio_chunks else b''