#!/usr/bin/env -S ../../../local-voice-ai-agent/.venv/bin/python
"""
Sofia Hotel Receptionist - FastRTC Stream Console Mode

Uses FastRTC's Stream with ReplyOnPause but without browser UI.
Pure console real-time voice like original LiveKit.
"""

import sys
import os
import uuid
import re
import logging
from datetime import datetime
import json

# Add project root to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

# Initialize logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s %(name)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S,%f'
)

# Import voice components
try:
    from fastrtc import get_stt_model, get_tts_model, ReplyOnPause, Stream
    VOICE_AVAILABLE = True
except ImportError:
    VOICE_AVAILABLE = False
    print("‚ùå FastRTC not available")
    sys.exit(1)

import ollama

# Import hotel functionality
from prompts.hotel.agent_instructions import AGENT_INSTRUCTION

# Create loggers
logger = logging.getLogger("agents.hotel.hotel_agent")
escalation_logger = logging.getLogger("core.escalation.escalation_triggers")

def log_json_message(level, message, **kwargs):
    log_data = {
        "timestamp": datetime.now().isoformat(),
        "level": level,
        "message": message,
        **kwargs
    }
    logger.info(json.dumps(log_data))

def register_escalation_trigger(trigger_id, escalation_type, priority):
    log_data = {
        "timestamp": datetime.now().isoformat(),
        "level": "INFO",
        "message": "Escalation trigger registered",
        "trigger_id": trigger_id,
        "escalation_type": escalation_type,
        "priority": priority
    }
    print(json.dumps(log_data))
    escalation_logger.info(json.dumps(log_data))

class SofiaStreamConsole:
    """Real-time console voice using FastRTC Stream"""

    def __init__(self):
        # Initialize escalation triggers
        self._register_all_escalation_triggers()

        print("üè® Starting Sofia Hotel AI Concierge...")
        print()

        # Initialize voice models
        print("üîÑ Loading voice models...")
        self.tts_model = get_tts_model()
        self.stt_model = get_stt_model()
        print("‚úÖ Voice models loaded")

        # Conversation state
        self.conversation_history = []
        self.conversation_id = None
        self.turn_count = 0

    def _register_all_escalation_triggers(self):
        triggers = [
            ("emergency_keywords", "security_concern", 100),
            ("complaint_keywords", "guest_complaint", 80),
            ("vip_indicators", "vip_guest", 75),
            ("payment_issues", "payment_issue", 70),
            ("system_errors", "system_failure", 90),
            ("booking_conflicts", "booking_conflict", 60),
            ("technical_issues", "technical_error", 50),
            ("maintenance_requests", "maintenance_request", 30),
            ("repeated_failures", "technical_error", 85),
            ("long_conversation", "unknown_request", 40),
            ("policy_exceptions", "policy_exception", 45),
        ]
        for trigger_id, escalation_type, priority in triggers:
            register_escalation_trigger(trigger_id, escalation_type, priority)

    def humanize_text_for_speech(self, text: str) -> str:
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251"
            "\U0001F900-\U0001F9FF\U0001FA70-\U0001FAFF]+", flags=re.UNICODE
        )
        text = emoji_pattern.sub(' ', text)
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        text = re.sub(r'`(.*?)`', r'\1', text)
        text = re.sub(r'#{1,6}\s*', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def get_hotel_ai_response(self, user_message: str) -> str:
        try:
            messages = [
                {"role": "system", "content": AGENT_INSTRUCTION},
                {"role": "assistant", "content": "Hello! I'm Sofia, your hotel concierge. How may I assist you today?"}
            ]

            for msg in self.conversation_history[-6:]:
                if msg.startswith("Guest: "):
                    messages.append({"role": "user", "content": msg[7:]})
                elif msg.startswith("Sofia: "):
                    messages.append({"role": "assistant", "content": msg[7:]})

            messages.append({"role": "user", "content": user_message})

            response = ollama.chat(
                model='gemma3:4b',
                messages=messages,
                options={'temperature': 0.7}
            )

            return response['message']['content']

        except Exception as e:
            logger.error(f"AI error: {e}")
            return "I apologize, I'm experiencing some technical difficulties. How else may I help you with your hotel needs?"

    def voice_handler(self, audio):
        """Handle real-time voice input from FastRTC Stream"""
        try:
            # Transcribe speech - FastRTC passes audio in correct format
            print("üîÑ Processing speech...")
            transcript = self.stt_model.stt(audio)

            print(f"‚úÖ STT returned: '{transcript}'")

            # Handle tuple return format if needed
            if isinstance(transcript, tuple):
                transcript = transcript[0] if transcript else ""

            if not transcript or not transcript.strip():
                print("‚ö†Ô∏è  No speech detected")
                return  # No speech detected, continue listening

            transcript = transcript.strip()
            self.turn_count += 1

            print(f"\n{'='*60}")
            print(f"[Turn {self.turn_count}]")
            print(f"üëÇ Guest said: {transcript}")
            print(f"{'='*60}\n")

            # Check for exit commands
            if transcript.lower() in ['goodbye', 'exit', 'quit', 'stop', 'auf wiedersehen']:
                print("\nüè® Sofia: Thank you for visiting Hotel L√§rchenhof. Auf Wiedersehen!")
                # Generate farewell audio
                farewell = "Thank you for visiting Hotel L√§rchenhof. Auf Wiedersehen!"
                for audio_chunk in self.tts_model.stream_tts_sync(farewell):
                    yield audio_chunk
                return

            # Update conversation history
            self.conversation_history.append(f"Guest: {transcript}")

            # Get AI response
            print("ü§î Sofia is thinking...")
            ai_response = self.get_hotel_ai_response(transcript)
            humanized_response = self.humanize_text_for_speech(ai_response)

            print(f"üè® Sofia: {humanized_response}")
            print(f"üîä Sofia speaking...")
            self.conversation_history.append(f"Sofia: {humanized_response}")

            # Generate and yield audio response (FastRTC handles playback)
            for audio_chunk in self.tts_model.stream_tts_sync(humanized_response):
                yield audio_chunk

            print(f"‚úÖ Response complete")
            print(f"\nüé§ Listening for next request...\n")

        except Exception as e:
            logger.error(f"Voice processing error: {e}")
            import traceback
            traceback.print_exc()

            error_msg = "I'm having trouble understanding. Could you please try again?"
            print(f"üè® Sofia: {error_msg}")
            for audio_chunk in self.tts_model.stream_tts_sync(error_msg):
                yield audio_chunk


def main():
    """Main function - real-time console receptionist using FastRTC Stream"""
    if len(sys.argv) > 1 and sys.argv[1] == "receptionist":
        print("============================================================")
        print("SOFIA HOTEL RECEPTIONIST - FASTRTC STREAM CONSOLE")
        print("REAL-TIME VOICE - JUST LIKE ORIGINAL LIVEKIT")
        print("============================================================")
        print("Real-time voice - Continuous listening")
        print("Professional hotel receptionist for front desk use")
        print("============================================================")
        print()
        print("Voice System: Local AI Stack (Private & Secure)")
        print("Speech Recognition: Moonshine STT (Real-time)")
        print("Voice Synthesis: Kokoro TTS")
        print("AI Brain: Ollama Gemma3 4B")
        print("Stream: FastRTC ReplyOnPause")
        print("============================================================")
        print()

        try:
            # Initialize Sofia Receptionist
            sofia = SofiaStreamConsole()

            conversation_id = f"hotel_stream_{uuid.uuid4().hex[:8]}"
            sofia.conversation_id = conversation_id

            log_json_message("INFO", "New hotel conversation initialized",
                            conversation_id=conversation_id)
            print(f"Conversation ID: {conversation_id}\n")

            # Play initial greeting
            greeting = "Guten Tag! Welcome to Hotel L√§rchenhof. I'm Sofia, your personal concierge. How may I help you today?"
            print(f"üè® Sofia: {greeting}")
            print("üîä Sofia speaking greeting...")

            for chunk in sofia.tts_model.stream_tts_sync(greeting):
                pass  # Audio plays automatically

            print("‚úÖ Greeting completed")
            print()

            print("==================================================" )
            print("     üé§ REAL-TIME VOICE MODE ACTIVE")
            print("==================================================")
            print("üó£Ô∏è  Speak naturally - Sofia listens continuously")
            print("üîä Sofia responds automatically when you pause")
            print("‚è∏Ô∏è  Say 'goodbye' or press Ctrl+C to exit")
            print()
            print("üé§ Listening continuously...")
            print()

            # Start real-time voice stream (like LiveKit)
            stream = Stream(
                ReplyOnPause(sofia.voice_handler),
                modality="audio",
                mode="send-receive"
            )

            # This launches the voice interface
            # Set share=False and quiet=True to minimize browser stuff
            print("üéôÔ∏è Starting FastRTC Stream...")
            stream.ui.launch(share=False, quiet=True, inbrowser=False)

        except KeyboardInterrupt:
            print("\n")
            print("üëã Session interrupted by user")
            print("‚úÖ Sofia Hotel Receptionist session ended")

        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()

    else:
        print("\n============================================================")
        print("SOFIA HOTEL RECEPTIONIST - FASTRTC STREAM CONSOLE")
        print("============================================================")
        print("üè® Voice-Only Receptionist")
        print("üé§ Real-time continuous voice")
        print("üîí Local AI - Private and secure\n")
        print("USAGE:")
        print("python sofia_stream_console.py receptionist\n")
        print("============================================================")


if __name__ == "__main__":
    main()